{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Week 2 - Measuring Boyer-Moore's benefit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class Boyer_Moore is provided by instructor Ben Langmead\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "\n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {alphabet[i]: i for i in range(len(alphabet))}\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "\n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        assert i < len(self.bad_char)\n",
    "        ci = self.amap[c]\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "\n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "\n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement versions of the naive exact matching and Boyer-Moore algorithms that additionally count and return (a) the number of character comparisons performed and (b) the number of alignments tried. Roughly speaking, these measure how much work the two different algorithms are doing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m wget http://d28rh4a8wq0iu5.cloudfront.net/ads1/code/bm_preproc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m wget http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boyer More function with counts\n",
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    \"\"\"\"p= pattern, t= text, p_bm=BoyerMoore object for p\"\"\"\n",
    "    i = 0\n",
    "\n",
    "    ## character comparisons performed and (b) the number of alignments tried##\n",
    "    num_character_comparisons = 0\n",
    "    num_alignments = 0\n",
    "    occurrences = [] # where p matched the t\n",
    "\n",
    "    while i < len(t) - len(p) + 1: #where t could start without running past p\n",
    "        num_alignments += 1\n",
    "        shift = 1 # indicate the amount that move along after comparison\n",
    "        mismatched = False #will update\n",
    "\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            num_character_comparisons += 1\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])  #shift using the bad character rule\n",
    "                skip_gs = p_bm.good_suffix_rule(j) #good rule, index of mismatch is j\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched: #if match text exactly\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences, num_alignments, num_character_comparisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 12 15\n"
     ]
    }
   ],
   "source": [
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 5 18\n"
     ]
    }
   ],
   "source": [
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 8]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Naive Exact Matches\n",
    "def Naive(p, t): #p reads sequence, t genome\n",
    "    occurrences = [] #create empty list for when p matches t\n",
    "    for i in range(len(t) - len(p) +1): #loop over alignments\n",
    "        match = True\n",
    "        for j in range(len(p)): #loop over characters\n",
    "            if not t[i+j] == p[j]:  #compare characters\n",
    "                match = False   #mismatch, reject aligment\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)   #all characters matched, record the list of occurrences\n",
    "    return occurrences\n",
    "\n",
    "t = \"AGCTAGCTAGC\"\n",
    "p = \"AG\"\n",
    "\n",
    "Naive(p,t) # these are the positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Naive Exact Matches with counts\n",
    "def naive_with_counts(p, t): #p reads sequence, t genome\n",
    "    \n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    occurrences = [] #create empty list for when p matches t\n",
    "\n",
    "    for i in range(len(t) - len(p) +1): #loop over alignments\n",
    "        num_alignments +=1\n",
    "        match = True\n",
    "\n",
    "        for j in range(len(p)): #loop over characters\n",
    "            num_character_comparisons +=1\n",
    "            if not t[i+j] == p[j]:  #compare characters\n",
    "                match = False   #mismatch, reject aligment\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)   #all characters matched, record the list of occurrences\n",
    "            \n",
    "    return occurrences, num_alignments, num_character_comparisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 41 46\n"
     ]
    }
   ],
   "source": [
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 20 35\n"
     ]
    }
   ],
   "source": [
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define function to read fa genome file\n",
    "def ReadGenome(filename):\n",
    "    genome = \"\"\n",
    "    with open(filename, \"r\") as f: #r for reading\n",
    "        for line in f:\n",
    "            if  not line[0] == \">\":\n",
    "                genome += line.rstrip() #remove whitespace\n",
    "    return genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Exact occurrences: [56922], number of alignments tried: 799954, number of charcter comparisons tried: 984143\n"
     ]
    }
   ],
   "source": [
    "# How many alignments does the naive exact matching algorithm try when matching the string \n",
    "# GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGGGGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\n",
    "# (derived from human Alu sequences) to the excerpt of human chromosome 1?\n",
    "\n",
    "\n",
    "## QUESTION 1 AND 2\n",
    "t = ReadGenome(\"chr1.GRCh38.excerpt.fasta\")\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "\n",
    "print(f\"Naive Exact occurrences: {occurrences}, number of alignments tried: {num_alignments}, number of charcter comparisons tried: {num_character_comparisons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boyer Moore occurrences: [56922], number of alignments tried: 127974, number of charcter comparisons tried: 165191\n"
     ]
    }
   ],
   "source": [
    "## QUESTION 3\n",
    "\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "\n",
    "print(f\"Boyer Moore occurrences: {occurrences}, number of alignments tried: {num_alignments}, number of charcter comparisons tried: {num_character_comparisons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boyer More function\n",
    "def boyer_moore(p, p_bm, t):\n",
    "    i = 0\n",
    "    occurrences = [] # where p matched the t\n",
    "    while i < len(t) - len(p) + 1: #where t could start without running past p\n",
    "        shift = 1 # indicate the amount that move along after comparison\n",
    "        mismatched = False #will update\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])  #shift using the bad character rule\n",
    "                skip_gs = p_bm.good_suffix_rule(j) #good rule, index of mismatch is j\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched: #if match text exactly\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTION 4\n",
    "\n",
    "## naive_2mm\n",
    "def naive_2mm(p, genome):\n",
    "    ocurrences = []\n",
    "\n",
    "    for i in range(len(genome) - len(p) + 1):  # loop\n",
    "        count_mismatch = 0\n",
    "        for j in range(len(p)):  # loop\n",
    "            if genome[i+j] != p[j]:\n",
    "                    count_mismatch +=1\n",
    "        if count_mismatch <=2:\n",
    "            ocurrences.append(i)\n",
    "    return ocurrences\n",
    "\n",
    "###########pidgeon hole\n",
    "\n",
    "def approximate_match(p, t, n):\n",
    "    segment_length = int(round(len(p) / (n + 1)))\n",
    "    all_matches = set()\n",
    "    p_idx = Index(t, segment_length)\n",
    "    idx_hits = 0\n",
    "    \n",
    "    for i in range(n + 1):\n",
    "        start = i * segment_length\n",
    "        end = min((i + 1) * segment_length, len(p))\n",
    "        matches = p_idx.query(p[start:end])\n",
    "\n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            idx_hits += 1\n",
    "            if m < start or m - start + len(p) > len(t):\n",
    "                continue\n",
    "\n",
    "            mismatches = 0\n",
    "\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m - start + j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m - start + j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), idx_hits\n",
    "\n",
    "#############\n",
    "def approximate_match_subseq(p, t, n, ival):\n",
    "    segment_length = int(round(len(p) / (n + 1)))\n",
    "    all_matches = set()\n",
    "    p_idx = SubseqIndex(t, segment_length, ival)\n",
    "    idx_hits = 0\n",
    "    for i in range(n + 1):\n",
    "        start = i\n",
    "        matches = p_idx.query(p[start:])\n",
    "\n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            idx_hits += 1\n",
    "            if m < start or m - start + len(p) > len(t):\n",
    "                continue\n",
    "\n",
    "            mismatches = 0\n",
    "\n",
    "            for j in range(0, len(p)):\n",
    "                if not p[j] == t[m - start + j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), idx_hits\n",
    "\n",
    "\n",
    "\n",
    "class Index(object):\n",
    "    def __init__(self, t, k):\n",
    "        ''' Create index from all substrings of size 'length' '''\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "    \n",
    "    def query(self, p):\n",
    "        ''' Return index hits for first k-mer of P '''\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "\n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences with up to 2 substitutions using Naive Exact: 19\n"
     ]
    }
   ],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "\n",
    "# Using naive_2mm to check the result.\n",
    "print(\"Occurences with up to 2 substitutions using Naive Exact:\", len(naive_2mm(p, t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurence with up to 2 substitutions using Boyer Moore: 19\n"
     ]
    }
   ],
   "source": [
    "matches, hits = approximate_match(p, t, 2)\n",
    "\n",
    "# Question 4\n",
    "print(\"Occurence with up to 2 substitutions using Boyer Moore:\", len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total index hits with up to 2 substitutions: 90\n"
     ]
    }
   ],
   "source": [
    "## Question 5\n",
    "print(\"Total index hits with up to 2 substitutions:\", hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total index hits with up to 2 substitutions, using subsequences: 79\n"
     ]
    }
   ],
   "source": [
    "# Question 6\n",
    "print(\"Total index hits with up to 2 substitutions, using subsequences:\", approximate_match_subseq(p, t, 2, 3)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
